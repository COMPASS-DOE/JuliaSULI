---
title: "EXCHANGE LULC Data"
output: html_document
date: "2023-02-27"
---

## Set-Up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
require(pacman)
pacman::p_load(tidyverse,
               raster,
               sp,
               rgdal,
               googledrive,
               janitor)
```

## Prepare EXCHANGE Site Coordinates

```{r}
# set location of metadata files
metadata_directory <- "https://drive.google.com/drive/folders/1IQUq_sD-Jama7ajaZl1zW_9zlWfyCohn"

# pull desired file name from GDrive folder and download it
metadata_file <- drive_ls(metadata_directory) %>%
  filter(grepl("Metadata_Collection", name)) %>%
  pull(name)

drive_download(metadata_file, overwrite = T)

# read in file and remove file from local directory
sample_locations_lat_long <- read_csv(metadata_file)

file.remove(metadata_file)

```

```{r}
# edit lat/long data file
sample_locations_lat_long <- sample_locations_lat_long %>%
  dplyr::select(kit_id, contains("latitude")|contains("longitude")) %>%
  pivot_longer(-kit_id, 
               names_to = c("transect_location", ".value"),
               names_pattern = "(.+)_(.+)") %>%
  mutate(transect_location = str_to_title(transect_location))

# write out as csv file to use for other spatial data work
#write_csv(sample_locations_lat_long, "kit_sample_locations_lat_long.csv")

```

```{r}
sample_locations_lat_long <- as.data.frame(sample_locations_lat_long)

# remove NA coordinates
sample_locations_noNA <- sample_locations_lat_long %>%
  filter(!(latitude %in% NA) | !(longitude %in% NA))

# cut data to just lat and long
lat_long <- dplyr::select(sample_locations_noNA, latitude, longitude)

# set lat and long to coordinates (make them a spatial object)
coordinates(lat_long) <- c("longitude", "latitude")

```

## C-CAP Land Cover Data

Dataset Citation:
National Oceanic and Atmospheric Administration, Office for Coastal Management. “Regional (30-meter) C-CAP Land Cover Data.” Coastal Change Analysis Program (C-CAP) Regional Land Cover. Charleston, SC: NOAA Office for Coastal Management. Accessed February 2023 at www.coast.noaa.gov/htdata/raster1/landcover/bulkdownload/30m_lc/.

A legend for the classification system used in this dataset was digitized in a .csv file based on this NOAA-provided document:
https://coast.noaa.gov/data/digitalcoast/pdf/ccap-class-scheme-regional.pdf

```{r}
# load tif file
ccap <- raster::raster("conus_2016_ccap_landcover_20200311.tif")

# pull CRS of the tif file
ccap_crs <- CRS(proj4string(ccap))

# assign some sort of CRS to the points (in this case the NAD83 reference)
proj4string(lat_long) <- CRS("+proj=longlat +ellps=GRS80 +datum=NAD83") 

# transform CRS to the ccap CRS to match
ccap_lat_long <- spTransform(lat_long, ccap_crs)

# export shapefile to double check R operations in QGIS
#raster::shapefile(ccap_lat_long, "./GIS Shapefiles/all_sample_sites_ccap.shp")

```

```{r}
# extract land cover information based on lat/long points
ccap_landcover <- extract(ccap, ccap_lat_long)

# merge this info back with site information
sample_locations_noNA$ccap_landcover_value <- ccap_landcover

# load the ccap key and then match definition for the extracted pixel values
ccap_key <- read_csv("C-CAP_land_cover_classification.csv")

CCAP_sample_locations <- sample_locations_noNA %>%
  left_join(ccap_key, by = c("ccap_landcover_value" = "pixel_value"))

```

## LANDFIRE Exisiting Vegetation Type Data

The classification key for this dataset was downloaded from:
https://www.landfire.gov/CSV/LF2020/LF20_EVC_220.csv

