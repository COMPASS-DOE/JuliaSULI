---
title: "EXCHANGE LULC Data"
output: html_document
date: "2023-02-27"
---

## Set-Up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
require(pacman)
pacman::p_load(tidyverse,
               raster,
               sp,
               rgdal,
               googledrive,
               janitor)
```

## Prepare EXCHANGE Site Coordinates

```{r}
# set location of metadata files
metadata_directory <- "https://drive.google.com/drive/folders/1IQUq_sD-Jama7ajaZl1zW_9zlWfyCohn"

# pull desired file name from GDrive folder and download it
metadata_file <- drive_ls(metadata_directory) %>%
  filter(grepl("Metadata_Collection", name)) %>%
  pull(name)

drive_download(metadata_file, overwrite = T)

# read in file and remove file from local directory
sample_locations_lat_long <- read_csv(metadata_file)

file.remove(metadata_file)

```

```{r}
# edit lat/long data file
sample_locations_lat_long <- sample_locations_lat_long %>%
  dplyr::select(kit_id, contains("latitude")|contains("longitude")) %>%
  pivot_longer(-kit_id, 
               names_to = c("transect_location", ".value"),
               names_pattern = "(.+)_(.+)") %>%
  mutate(transect_location = str_to_title(transect_location))

# write out as csv file to use for other spatial data work
#write_csv(sample_locations_lat_long, "kit_sample_locations_lat_long.csv")

```

```{r}
sample_locations_lat_long <- as.data.frame(sample_locations_lat_long)

# remove NA coordinates
sample_locations_noNA <- sample_locations_lat_long %>%
  filter(!(latitude %in% NA) | !(longitude %in% NA))

# cut data to just lat and long
lat_long <- dplyr::select(sample_locations_noNA, latitude, longitude)

# set lat and long to coordinates (make them a spatial object)
coordinates(lat_long) <- c("longitude", "latitude")

```

## C-CAP Land Cover Data

Dataset Citation:
National Oceanic and Atmospheric Administration, Office for Coastal Management. “Regional (30-meter) C-CAP Land Cover Data.” Coastal Change Analysis Program (C-CAP) Regional Land Cover. Charleston, SC: NOAA Office for Coastal Management. Accessed February 2023 at www.coast.noaa.gov/htdata/raster1/landcover/bulkdownload/30m_lc/.

A legend for the classification system used in this dataset was digitized in a .csv file based on this NOAA-provided document:
https://coast.noaa.gov/data/digitalcoast/pdf/ccap-class-scheme-regional.pdf

```{r}
# load tif file
# not in GitHub repo because it's a VERY large file - will need to be downloaded to local repository
ccap <- raster::raster("conus_2016_ccap_landcover_20200311.tif")

# pull CRS of the tif file
ccap_crs <- CRS(proj4string(ccap))

# assign some sort of CRS to the points (in this case the NAD83 reference)
proj4string(lat_long) <- CRS("+proj=longlat +ellps=GRS80 +datum=NAD83") 

# transform CRS to the ccap CRS to match
ccap_lat_long <- spTransform(lat_long, ccap_crs)

# export shapefile to double check R operations in QGIS
#raster::shapefile(ccap_lat_long, "./GIS Shapefiles/all_sample_sites_ccap.shp")

```

```{r}
# extract land cover information based on lat/long points
ccap_landcover <- raster::extract(ccap, ccap_lat_long)

# merge this info back with site information
sample_locations_noNA$ccap_landcover_value <- ccap_landcover

# load the ccap key and then match definition for the extracted pixel values
ccap_key <- read_csv("C-CAP_land_cover_classification.csv")

CCAP_sample_locations <- sample_locations_noNA %>%
  left_join(ccap_key, by = c("ccap_landcover_value" = "pixel_value"))

```

## LANDFIRE Exisiting Vegetation Type Data

Data Description: https://www.landfire.gov/evt.php
Metadata: https://www.landfire.gov/metadata/lf2020/CONUS/LC20_EVT_220.html
Download Site: https://www.landfire.gov/version_download.php#

The classification key for this dataset was downloaded from:
https://www.landfire.gov/CSV/LF2020/LF20_EVC_220.csv
This document contains LOTS of detail about the vegetation classifications...
https://www.landfire.gov/documents/LANDFIRE_Ecological_Systems_Descriptions_CONUS.pdf

```{r}
# load tif file
# also not in online GitHub repo - too large
evt <- raster::raster("LC20_EVT_220.tif")

# pull CRS of of the tif file
evt_crs <- CRS(proj4string(evt))

# reproject lat_long CRS to match tif file
evt_lat_long <- spTransform(lat_long, evt_crs)

# extract ecosystem information
evt_ecosystem <- raster::extract(evt, evt_lat_long)

# merge info back with kit location info
sample_locations_noNA$evt_value <- evt_ecosystem

# load in EVT key
evt_key <- read_csv("LANDFIRE2020_EVT_classification.csv")

# edit key column names based on data attributes description from source
colnames(evt_key) <- c("value", "ecological_system_name", "lifeform_code", "fuel_code", 
                       "fuel_name", "vegetation_lifeform", "vegetation_physiognomy", "vegetation_group_code",
                       "vegetation_group", "dominant_vegetation_cover_type", "vegetation_order",
                       "vegetation_class", "vegetation_subclass", "R", "G", "B", "RED", "GREEN", "BLUE")

# cut down on columns to describe the extracted value
evt_key_edit <- evt_key %>%
  select(-contains("code"), -contains("fuel"), -R, -G, -B, -RED, -BLUE, -GREEN)

# produce data frame with vegetation type descriptions
EVT_sample_locations <- sample_locations_noNA %>%
  select(-ccap_landcover_value) %>%
  left_join(evt_key_edit, by = c("evt_value" = "value"))

# create data file to double check extracted values
LC_check <- CCAP_sample_locations %>%
  select(-ccap_landcover_value) %>%
  left_join(select(EVT_sample_locations, kit_id:longitude, ecological_system_name),
            by = c("kit_id", "transect_location", "latitude", "longitude"))
```


